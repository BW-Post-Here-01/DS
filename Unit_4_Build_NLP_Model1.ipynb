{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here is a model for NLP that allows us to clean data and correctly categorize each post from reddit as it was classified.  Step by step the model will:\n",
    "1) clean and process data\n",
    "2) vectorize data\n",
    "3) fit a model with spacy\n",
    "4) score the model with a confusion matrix\n",
    "5) test the model\n",
    "6) pickle the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\tcnick12\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data, mined by Jonathan\n",
    "url = 'https://raw.githubusercontent.com/BW-Post-Here-01/DS/master/Data/reddit_data_slimmed.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>COMMUNITY ANNOUNCEMENT In solidarity with the ...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Weekly r/Tattoos Question/FreeTalk Thread! - A...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Enter Shikari and Architects album artwork and...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>David Bowie Portrait - Healed, Done in April 2...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Photo realism artist chicago As the title sugg...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Can you do colorful Japanese/Yakuza tattoos on...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Tattoo Commission Question. Seperate Artist an...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Weekly r/Tattoos Question/FreeTalk Thread! - A...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Partial cover up / adding to a design with a d...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Lately I realized, that very famous people, ha...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>Sacramento area artists? Hello, so after the q...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>ISO Canadian Fish / Wildlife Artist around the...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>As a client, what should I provide my artist w...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Sleeve thoughts Hello fellow redditors! I have...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Weekly r/Tattoos Question/FreeTalk Thread! - A...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>Healed tattoo I got about 2 years ago at Liqui...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>Etiquette- bringing your own design? So I’ve b...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>Art recommendations in the style of Gustave Do...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>Photo Realistic Artists NYC? Hey guys, for my ...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>Any recommendations for a pop culture/gaming a...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>Weekly r/Tattoos Question/FreeTalk Thread! - A...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Artist/studio recommendation Brussel/Antwerp H...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Unemployment for tattoo artists I know most of...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>how to get a design? been looking to get my fi...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>How do I choose the right artist? I’m getting ...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content subreddit\n",
       "0   COMMUNITY ANNOUNCEMENT In solidarity with the ...   tattoos\n",
       "1   Weekly r/Tattoos Question/FreeTalk Thread! - A...   tattoos\n",
       "2   Enter Shikari and Architects album artwork and...   tattoos\n",
       "3   David Bowie Portrait - Healed, Done in April 2...   tattoos\n",
       "4   Photo realism artist chicago As the title sugg...   tattoos\n",
       "5   Can you do colorful Japanese/Yakuza tattoos on...   tattoos\n",
       "6   Tattoo Commission Question. Seperate Artist an...   tattoos\n",
       "7   Weekly r/Tattoos Question/FreeTalk Thread! - A...   tattoos\n",
       "8   Partial cover up / adding to a design with a d...   tattoos\n",
       "9   Lately I realized, that very famous people, ha...   tattoos\n",
       "10  Sacramento area artists? Hello, so after the q...   tattoos\n",
       "11  ISO Canadian Fish / Wildlife Artist around the...   tattoos\n",
       "12  As a client, what should I provide my artist w...   tattoos\n",
       "13  Sleeve thoughts Hello fellow redditors! I have...   tattoos\n",
       "14  Weekly r/Tattoos Question/FreeTalk Thread! - A...   tattoos\n",
       "15  Healed tattoo I got about 2 years ago at Liqui...   tattoos\n",
       "16  Etiquette- bringing your own design? So I’ve b...   tattoos\n",
       "17  Art recommendations in the style of Gustave Do...   tattoos\n",
       "18  Photo Realistic Artists NYC? Hey guys, for my ...   tattoos\n",
       "19  Any recommendations for a pop culture/gaming a...   tattoos\n",
       "20  Weekly r/Tattoos Question/FreeTalk Thread! - A...   tattoos\n",
       "21  Artist/studio recommendation Brussel/Antwerp H...   tattoos\n",
       "22  Unemployment for tattoo artists I know most of...   tattoos\n",
       "23  how to get a design? been looking to get my fi...   tattoos\n",
       "24  How do I choose the right artist? I’m getting ...   tattoos"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize df\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data with this function\n",
    "def cleaning_fn(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    4. Returns in lowercase.\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    clean = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    clean = ''.join(clean)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in clean.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['clean_content'] = df['content'].apply(cleaning_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_clean = pd.DataFrame(df['clean_content'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>COMMUNITY ANNOUNCEMENT In solidarity with the ...</td>\n",
       "      <td>tattoos</td>\n",
       "      <td>[COMMUNITY, ANNOUNCEMENT, solidarity, many, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Weekly r/Tattoos Question/FreeTalk Thread! - A...</td>\n",
       "      <td>tattoos</td>\n",
       "      <td>[Weekly, rTattoos, QuestionFreeTalk, Thread, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Enter Shikari and Architects album artwork and...</td>\n",
       "      <td>tattoos</td>\n",
       "      <td>[Enter, Shikari, Architects, album, artwork, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>David Bowie Portrait - Healed, Done in April 2...</td>\n",
       "      <td>tattoos</td>\n",
       "      <td>[David, Bowie, Portrait, Healed, Done, April, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Photo realism artist chicago As the title sugg...</td>\n",
       "      <td>tattoos</td>\n",
       "      <td>[Photo, realism, artist, chicago, title, sugge...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content subreddit  \\\n",
       "0  COMMUNITY ANNOUNCEMENT In solidarity with the ...   tattoos   \n",
       "1  Weekly r/Tattoos Question/FreeTalk Thread! - A...   tattoos   \n",
       "2  Enter Shikari and Architects album artwork and...   tattoos   \n",
       "3  David Bowie Portrait - Healed, Done in April 2...   tattoos   \n",
       "4  Photo realism artist chicago As the title sugg...   tattoos   \n",
       "\n",
       "                                       clean_content  \n",
       "0  [COMMUNITY, ANNOUNCEMENT, solidarity, many, co...  \n",
       "1  [Weekly, rTattoos, QuestionFreeTalk, Thread, A...  \n",
       "2  [Enter, Shikari, Architects, album, artwork, g...  \n",
       "3  [David, Bowie, Portrait, Healed, Done, April, ...  \n",
       "4  [Photo, realism, artist, chicago, title, sugge...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the rows of the df so we don't have the iloc 1-100 all classified\n",
    "# as one class, the next 200 as another, etc., so we don't have issues with\n",
    "# a train/test split\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Did NASA nuke Saturn? NASA just sent Cassini t...</td>\n",
       "      <td>askscience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>[Spoilers] Not my ending I remember reading [T...</td>\n",
       "      <td>gameofthrones</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>The final discovery: Spaniard and russian enco...</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Why hasn't anyone made a small attachable scre...</td>\n",
       "      <td>Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>PWM Fan Hub need to be set as PWM in Bios? My ...</td>\n",
       "      <td>buildapc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content      subreddit\n",
       "0  Did NASA nuke Saturn? NASA just sent Cassini t...     askscience\n",
       "1  [Spoilers] Not my ending I remember reading [T...  gameofthrones\n",
       "2  The final discovery: Spaniard and russian enco...        history\n",
       "3  Why hasn't anyone made a small attachable scre...        Android\n",
       "4  PWM Fan Hub need to be set as PWM in Bios? My ...       buildapc"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the df['subreddit'] is no longer grouped by class but it sorted at random.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The actual predictive model with three examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25652,)\n",
      "(25652,)\n",
      "(6413,)\n",
      "(6413,)\n"
     ]
    }
   ],
   "source": [
    "# Apply train/test split\n",
    "X = df['content']\n",
    "y = df['subreddit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('classifier', RandomForestClassifier()),  # Originally trained with MulinomialNB() but had low accuracy\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcnick12\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit X_train and y_train on the pipe\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "          Android       0.25      0.24      0.24        58\n",
      "              DIY       0.06      0.06      0.06        31\n",
      "          Fitness       0.49      0.63      0.55       208\n",
      "       Futurology       0.06      0.04      0.05        26\n",
      "            Games       0.29      0.14      0.19        42\n",
      "     GetMotivated       0.38      0.21      0.27        14\n",
      "             IAmA       0.52      0.89      0.65       231\n",
      "            Jokes       0.26      0.44      0.32       383\n",
      "      LifeProTips       0.51      0.60      0.55       184\n",
      "  MachineLearning       0.67      0.58      0.62       209\n",
      "            Music       0.22      0.14      0.17        59\n",
      "        Overwatch       0.20      0.13      0.16        77\n",
      "              PS4       0.37      0.43      0.40       121\n",
      "   Showerthoughts       0.11      0.04      0.06        26\n",
      "           Tinder       0.67      0.09      0.16        22\n",
      "  TwoXChromosomes       0.28      0.30      0.29       263\n",
      "   WritingPrompts       0.57      0.17      0.26        47\n",
      "       askscience       0.28      0.34      0.31       236\n",
      "          atheism       0.42      0.24      0.31       127\n",
      "            books       0.55      0.40      0.46       154\n",
      "         buildapc       0.58      0.72      0.64       389\n",
      "         dadjokes       0.33      0.64      0.44       354\n",
      "           europe       0.00      0.00      0.00         8\n",
      "explainlikeimfive       0.65      0.40      0.50       127\n",
      "          gadgets       0.00      0.00      0.00        11\n",
      "    gameofthrones       0.66      0.27      0.38        78\n",
      "           gaming       0.15      0.04      0.06        56\n",
      "          history       0.42      0.48      0.45       276\n",
      "  leagueoflegends       0.42      0.22      0.29       192\n",
      "        lifehacks       0.17      0.03      0.05        36\n",
      "     listentothis       0.67      0.12      0.21        16\n",
      "malefashionadvice       0.89      0.37      0.52        89\n",
      "           movies       0.52      0.24      0.33        67\n",
      "              nba       0.71      0.36      0.48       155\n",
      "          nosleep       0.80      0.92      0.86       348\n",
      "     pcmasterrace       0.13      0.04      0.07        89\n",
      "  personalfinance       0.56      0.61      0.58       366\n",
      "       philosophy       1.00      0.33      0.50        18\n",
      "          pokemon       0.36      0.10      0.16        88\n",
      "         politics       1.00      1.00      1.00        11\n",
      "    relationships       0.57      0.65      0.61       278\n",
      "           soccer       0.56      0.24      0.33        21\n",
      "            space       0.25      0.03      0.06        32\n",
      "          tattoos       1.00      0.20      0.33         5\n",
      "       technology       0.00      0.00      0.00         4\n",
      "       television       0.60      0.04      0.07        79\n",
      "             tifu       0.63      0.61      0.62       323\n",
      "           travel       0.58      0.33      0.42       151\n",
      "            trees       0.09      0.01      0.02        77\n",
      "           webdev       0.59      0.23      0.33       151\n",
      "\n",
      "         accuracy                           0.47      6413\n",
      "        macro avg       0.44      0.31      0.33      6413\n",
      "     weighted avg       0.48      0.47      0.45      6413\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcnick12\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline prediction object with X_test\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "# Score the model with X_test and y_test\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tattoos', 'technology', 'gadgets', 'europe', 'GetMotivated',\n",
       "       'philosophy', 'listentothis', 'politics', 'soccer', 'Tinder',\n",
       "       'Futurology', 'space', 'Showerthoughts', 'DIY', 'Games',\n",
       "       'WritingPrompts', 'lifehacks', 'gaming', 'Android', 'trees',\n",
       "       'Music', 'malefashionadvice', 'television', 'gameofthrones',\n",
       "       'movies', 'pokemon', 'Overwatch', 'pcmasterrace',\n",
       "       'explainlikeimfive', 'atheism', 'PS4', 'books', 'nba', 'webdev',\n",
       "       'travel', 'LifeProTips', 'MachineLearning', 'leagueoflegends',\n",
       "       'Fitness', 'askscience', 'IAmA', 'TwoXChromosomes',\n",
       "       'relationships', 'history', 'tifu', 'dadjokes', 'nosleep',\n",
       "       'personalfinance', 'Jokes', 'buildapc'], dtype=object)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at these categories, try four fake reviews and see how the model does:\n",
    "df.subreddit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fn that takes in a reddit post and returns the top five most likely categories:\n",
    "def get_predictions(post, num_answers=5):\n",
    "  \"\"\" takes a post and returns the top categories it fits in \"\"\"\n",
    "\n",
    "  # get the predicted probabilities for each class\n",
    "  preds = pd.Series(pipeline.predict_proba(post)[0])\n",
    "\n",
    "  # save each class to the Series index\n",
    "  preds.index = pipeline.classes_\n",
    "\n",
    "  # sort to get the most likely classes\n",
    "  preds = preds.sort_values(ascending=False)\n",
    "\n",
    "  # return the top num_answers results in dict format\n",
    "  return preds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test one with a fake review about history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a fake review\n",
    "history_post = [ \"\"\"\n",
    "                History if my favorite subject.  I love to read historical accounts about ancient Rome and Greece.\n",
    "                I'm also a big World War 2 buff and I collect objects with historical significance.\n",
    "                \"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "history       0.5\n",
       "dadjokes      0.1\n",
       "buildapc      0.1\n",
       "gaming        0.1\n",
       "askscience    0.1\n",
       "dtype: float64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(history_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test two with a fake review about pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try again and mention pokemon to see if the model correctly guesses pokemon:\n",
    "pokemon_post = [ \"\"\"\n",
    "                My favorite pokemon are pikachu and charizard.\n",
    "                \"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dadjokes    0.7\n",
       "Jokes       0.2\n",
       "pokemon     0.1\n",
       "webdev      0.0\n",
       "PS4         0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(pokemon_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test three with a fake post about android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a fake prediction to see if android gets predicted:\n",
    "android_post = [ \"\"\"\n",
    "                I use a galaxy note 5.  My favorite opperating system version was oreo.\n",
    "                Android phones are better than iphones. I like to create apps for the app store.\n",
    "                \"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android         0.4\n",
       "Jokes           0.3\n",
       "pcmasterrace    0.1\n",
       "askscience      0.1\n",
       "pokemon         0.1\n",
       "dtype: float64"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(android_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test four with a fake post about music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a fake prediction to see if music gets predicted:\n",
    "music_post = [ \"\"\"\n",
    "                I love to listen to music.  My favorite singer/songwriter is Foy Vance.  Every so often\n",
    "                I like to listen to Bob Marley.  I have a large vinyl music collection but more recently I've\n",
    "                been listening to everything on Spotify.\n",
    "                \"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "askscience    0.2\n",
       "Music         0.2\n",
       "PS4           0.1\n",
       "Jokes         0.1\n",
       "history       0.1\n",
       "dtype: float64"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(music_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "# save the model\n",
    "dump(pipeline, open('reddit_model_nc.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to load in the model again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import load\n",
    "# load the model\n",
    "loaded_model = load(open('reddit_model.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the Flask app API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example code meant to be in a Flask app.  Won't run on colab\n",
    "\n",
    "from pickle import load\n",
    "# load the model\n",
    "loaded_model = load(open('reddit_model.pkl', 'rb'))\n",
    "\n",
    "\n",
    "from flask import jsonify\n",
    "\n",
    "@app.route(\"/predict.json\", methods=[\"POST\"])\n",
    "def predict():\n",
    "  print(\"PREDICT ROUTE...\")\n",
    "  print(\"FORM DATA:\", dict(request.form))\n",
    "  #> {'title': 'example title', 'text': 'Example reddit post text here'}\n",
    "\n",
    "  # concatenate title and text, passed in as one variable to the model\n",
    "  post = request.form[\"title\"] + ' ' + screen_name_b = request.form[\"text\"]\n",
    "\n",
    "  # get predictions, store as a Pandas Series\n",
    "  preds = pd.Series(loaded_model.predict_proba(music_post)[0])\n",
    "\n",
    "  # assign the subreddit classes to the index\n",
    "  preds.index = loaded_model.classes_\n",
    "\n",
    "  # sort by values to get the top results\n",
    "  preds = preds.sort_values(ascending=False)\n",
    "\n",
    "  # return the top 5 results as JSON\n",
    "  return jsonify(subreddits=preds.index[:5],\n",
    "                  probabilities=preds[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sklearn Version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.21.3'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.__version__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
