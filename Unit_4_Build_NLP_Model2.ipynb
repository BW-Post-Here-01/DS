{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in data, mined by Jonathan\n",
    "url = 'https://raw.githubusercontent.com/BW-Post-Here-01/DS/master/Data/reddit_data_slimmed.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>COMMUNITY ANNOUNCEMENT In solidarity with the ...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Weekly r/Tattoos Question/FreeTalk Thread! - A...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Enter Shikari and Architects album artwork and...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>David Bowie Portrait - Healed, Done in April 2...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Photo realism artist chicago As the title sugg...</td>\n",
       "      <td>tattoos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content subreddit\n",
       "0  COMMUNITY ANNOUNCEMENT In solidarity with the ...   tattoos\n",
       "1  Weekly r/Tattoos Question/FreeTalk Thread! - A...   tattoos\n",
       "2  Enter Shikari and Architects album artwork and...   tattoos\n",
       "3  David Bowie Portrait - Healed, Done in April 2...   tattoos\n",
       "4  Photo realism artist chicago As the title sugg...   tattoos"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tattoos', 'technology', 'gadgets', 'europe', 'GetMotivated',\n",
       "       'philosophy', 'listentothis', 'politics', 'soccer', 'Tinder',\n",
       "       'Futurology', 'space', 'Showerthoughts', 'DIY', 'Games',\n",
       "       'WritingPrompts', 'lifehacks', 'gaming', 'Android', 'trees',\n",
       "       'Music', 'malefashionadvice', 'television', 'gameofthrones',\n",
       "       'movies', 'pokemon', 'Overwatch', 'pcmasterrace',\n",
       "       'explainlikeimfive', 'atheism', 'PS4', 'books', 'nba', 'webdev',\n",
       "       'travel', 'LifeProTips', 'MachineLearning', 'leagueoflegends',\n",
       "       'Fitness', 'askscience', 'IAmA', 'TwoXChromosomes',\n",
       "       'relationships', 'history', 'tifu', 'dadjokes', 'nosleep',\n",
       "       'personalfinance', 'Jokes', 'buildapc'], dtype=object)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.subreddit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df.loc[df['subreddit']=='tattoos'].index, inplace=True)\n",
    "df.drop(df.loc[df['subreddit']=='trees'].index, inplace=True)\n",
    "df.drop(df.loc[df['subreddit']=='space'].index, inplace=True)\n",
    "df.drop(df.loc[df['subreddit']=='pcmasterrace'].index, inplace=True)\n",
    "df.drop(df.loc[df['subreddit']=='lifehacks'].index, inplace=True)\n",
    "df.drop(df.loc[df['subreddit']=='Overwatch'].index, inplace=True)\n",
    "df.drop(df.loc[df['subreddit']=='gaming'].index, inplace=True)\n",
    "df.drop(df.loc[df['subreddit']=='gadgets'].index, inplace=True)\n",
    "df.drop(df.loc[df['subreddit']=='Showerthoughts'].index, inplace=True)\n",
    "df.drop(df.loc[df['subreddit']=='Futurology'].index, inplace=True)\n",
    "df.drop(df.loc[df['subreddit']=='Tinder'].index, inplace=True)\n",
    "df.drop(df.loc[df['subreddit']=='DIY'].index, inplace=True)\n",
    "df.drop(df.loc[df['subreddit']=='television'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['technology', 'europe', 'GetMotivated', 'philosophy',\n",
       "       'listentothis', 'politics', 'soccer', 'Games', 'WritingPrompts',\n",
       "       'Android', 'Music', 'malefashionadvice', 'gameofthrones', 'movies',\n",
       "       'pokemon', 'explainlikeimfive', 'atheism', 'PS4', 'books', 'nba',\n",
       "       'webdev', 'travel', 'LifeProTips', 'MachineLearning',\n",
       "       'leagueoflegends', 'Fitness', 'askscience', 'IAmA',\n",
       "       'TwoXChromosomes', 'relationships', 'history', 'tifu', 'dadjokes',\n",
       "       'nosleep', 'personalfinance', 'Jokes', 'buildapc'], dtype=object)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.subreddit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process data with this function\n",
    "def cleaning_fn(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    4. Returns in lowercase.\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    clean = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    clean = ''.join(clean)\n",
    "\n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in clean.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomize the rows of the df so we don't have the iloc 1-100 all classified\n",
    "# as one class, the next 200 as another, etc., so we don't have issues with\n",
    "# a train/test split\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>[D] Video Analysis - Backpropagation and the b...</td>\n",
       "      <td>MachineLearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Couples who are newly living together: how do ...</td>\n",
       "      <td>TwoXChromosomes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>[D] Intel removed MKL_DEBUG_CPU_TYPE workaroun...</td>\n",
       "      <td>MachineLearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Idea for Gen 5 remake. So I've had this idea f...</td>\n",
       "      <td>pokemon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Feedback? PCPartPicker Part List: https://pcpa...</td>\n",
       "      <td>buildapc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>I am Victoria from reddit. AMAA! [proof](http:...</td>\n",
       "      <td>IAmA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Lump Some or Pension? Hi if there was a opport...</td>\n",
       "      <td>personalfinance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Haitian slave rebellion As opposed to being a ...</td>\n",
       "      <td>history</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Weird shit I've seen as a Marine 2b Weird shit...</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Schengen Visa question? Hello! I am hoping to ...</td>\n",
       "      <td>travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>I have a really dark joke about light waves ch...</td>\n",
       "      <td>dadjokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>Is it possible to live off 2k a month by mysel...</td>\n",
       "      <td>personalfinance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>My Parents Sold Me When I Was 7 Our monthly st...</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>Last night I let my dog outside, but something...</td>\n",
       "      <td>nosleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>Online support not working I can’t even get th...</td>\n",
       "      <td>PS4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>[R] Facebook, Carnegie Mellon build first AI t...</td>\n",
       "      <td>MachineLearning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>First PC Build Hey guys\\n\\nI am quite new to t...</td>\n",
       "      <td>buildapc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>I'm Tory Belleci, co-host of White Rabbit Proj...</td>\n",
       "      <td>IAmA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>What are my approval odds? What are my approva...</td>\n",
       "      <td>personalfinance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>I was in a porno cinema the other night. I had...</td>\n",
       "      <td>Jokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>My best friend (25/F) thinks I (25/F) ruined a...</td>\n",
       "      <td>relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>Parts list for first build https://pcpartpicke...</td>\n",
       "      <td>buildapc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>Have you heard of whiteboards? They're a prett...</td>\n",
       "      <td>dadjokes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>Who would you rather take as a first option, P...</td>\n",
       "      <td>nba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>[R][P] Talking Head Anime from a Single Image ...</td>\n",
       "      <td>MachineLearning</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              content        subreddit\n",
       "0   [D] Video Analysis - Backpropagation and the b...  MachineLearning\n",
       "1   Couples who are newly living together: how do ...  TwoXChromosomes\n",
       "2   [D] Intel removed MKL_DEBUG_CPU_TYPE workaroun...  MachineLearning\n",
       "3   Idea for Gen 5 remake. So I've had this idea f...          pokemon\n",
       "4   Feedback? PCPartPicker Part List: https://pcpa...         buildapc\n",
       "5   I am Victoria from reddit. AMAA! [proof](http:...             IAmA\n",
       "6   Lump Some or Pension? Hi if there was a opport...  personalfinance\n",
       "7   Haitian slave rebellion As opposed to being a ...          history\n",
       "8   Weird shit I've seen as a Marine 2b Weird shit...          nosleep\n",
       "9   Schengen Visa question? Hello! I am hoping to ...           travel\n",
       "10  I have a really dark joke about light waves ch...         dadjokes\n",
       "11  Is it possible to live off 2k a month by mysel...  personalfinance\n",
       "12  My Parents Sold Me When I Was 7 Our monthly st...          nosleep\n",
       "13  Last night I let my dog outside, but something...          nosleep\n",
       "14  Online support not working I can’t even get th...              PS4\n",
       "15  [R] Facebook, Carnegie Mellon build first AI t...  MachineLearning\n",
       "16  First PC Build Hey guys\\n\\nI am quite new to t...         buildapc\n",
       "17  I'm Tory Belleci, co-host of White Rabbit Proj...             IAmA\n",
       "18  What are my approval odds? What are my approva...  personalfinance\n",
       "19  I was in a porno cinema the other night. I had...            Jokes\n",
       "20  My best friend (25/F) thinks I (25/F) ruined a...    relationships\n",
       "21  Parts list for first build https://pcpartpicke...         buildapc\n",
       "22  Have you heard of whiteboards? They're a prett...         dadjokes\n",
       "23  Who would you rather take as a first option, P...              nba\n",
       "24  [R][P] Talking Head Anime from a Single Image ...  MachineLearning"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23350,)\n",
      "(5838,)\n",
      "(23350,)\n",
      "(5838,)\n"
     ]
    }
   ],
   "source": [
    "# Apply train/test split\n",
    "X = df['content']\n",
    "y = df['subreddit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(stop_words='english')),\n",
    "    ('classifier', RandomForestClassifier()),  # Originally trained with MulinomialNB() but had low accuracy\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcnick12\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patt...\n",
       "                 RandomForestClassifier(bootstrap=True, class_weight=None,\n",
       "                                        criterion='gini', max_depth=None,\n",
       "                                        max_features='auto',\n",
       "                                        max_leaf_nodes=None,\n",
       "                                        min_impurity_decrease=0.0,\n",
       "                                        min_impurity_split=None,\n",
       "                                        min_samples_leaf=1, min_samples_split=2,\n",
       "                                        min_weight_fraction_leaf=0.0,\n",
       "                                        n_estimators=10, n_jobs=None,\n",
       "                                        oob_score=False, random_state=None,\n",
       "                                        verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit X_train and y_train on the pipe\n",
    "pipeline.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "          Android       0.55      0.52      0.54        63\n",
      "          Fitness       0.62      0.75      0.68       210\n",
      "            Games       0.33      0.08      0.13        37\n",
      "     GetMotivated       0.50      0.15      0.24        13\n",
      "             IAmA       0.64      0.91      0.75       247\n",
      "            Jokes       0.29      0.51      0.37       366\n",
      "      LifeProTips       0.68      0.63      0.65       202\n",
      "  MachineLearning       0.71      0.71      0.71       185\n",
      "            Music       0.29      0.23      0.25        53\n",
      "              PS4       0.66      0.66      0.66       150\n",
      "  TwoXChromosomes       0.37      0.32      0.34       245\n",
      "   WritingPrompts       0.86      0.39      0.53        31\n",
      "       askscience       0.45      0.39      0.42       228\n",
      "          atheism       0.72      0.46      0.56       137\n",
      "            books       0.66      0.59      0.63       133\n",
      "         buildapc       0.79      0.87      0.83       380\n",
      "         dadjokes       0.36      0.62      0.45       342\n",
      "           europe       0.50      0.08      0.14        12\n",
      "explainlikeimfive       0.81      0.57      0.67       136\n",
      "    gameofthrones       0.77      0.76      0.76        74\n",
      "          history       0.66      0.57      0.61       299\n",
      "  leagueoflegends       0.61      0.43      0.51       211\n",
      "     listentothis       0.00      0.00      0.00        19\n",
      "malefashionadvice       0.86      0.49      0.62        74\n",
      "           movies       0.76      0.20      0.31        82\n",
      "              nba       0.82      0.56      0.66       136\n",
      "          nosleep       0.82      0.93      0.87       363\n",
      "  personalfinance       0.68      0.64      0.66       355\n",
      "       philosophy       1.00      0.50      0.67        14\n",
      "          pokemon       0.79      0.32      0.46        68\n",
      "         politics       1.00      1.00      1.00        14\n",
      "    relationships       0.72      0.68      0.70       301\n",
      "           soccer       0.86      0.30      0.44        20\n",
      "       technology       0.00      0.00      0.00         6\n",
      "             tifu       0.76      0.71      0.73       337\n",
      "           travel       0.73      0.44      0.55       153\n",
      "           webdev       0.71      0.36      0.48       142\n",
      "\n",
      "         accuracy                           0.61      5838\n",
      "        macro avg       0.63      0.50      0.53      5838\n",
      "     weighted avg       0.64      0.61      0.60      5838\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tcnick12\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline prediction object with X_test\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "# Score the model with X_test and y_test\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['MachineLearning', 'TwoXChromosomes', 'pokemon', 'buildapc',\n",
       "       'IAmA', 'personalfinance', 'history', 'nosleep', 'travel',\n",
       "       'dadjokes', 'PS4', 'Jokes', 'relationships', 'nba', 'Fitness',\n",
       "       'leagueoflegends', 'tifu', 'explainlikeimfive', 'books', 'webdev',\n",
       "       'soccer', 'Music', 'LifeProTips', 'WritingPrompts', 'atheism',\n",
       "       'movies', 'askscience', 'malefashionadvice', 'gameofthrones',\n",
       "       'Android', 'politics', 'europe', 'philosophy', 'technology',\n",
       "       'listentothis', 'GetMotivated', 'Games'], dtype=object)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at these categories, try four fake reviews and see how the model does:\n",
    "df.subreddit.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fn that takes in a reddit post and returns the top five most likely categories:\n",
    "def get_predictions(post, num_answers=5):\n",
    "  \"\"\" takes a post and returns the top categories it fits in \"\"\"\n",
    "\n",
    "  # get the predicted probabilities for each class\n",
    "  preds = pd.Series(pipeline.predict_proba(post)[0])\n",
    "\n",
    "  # save each class to the Series index\n",
    "  preds.index = pipeline.classes_\n",
    "\n",
    "  # sort to get the most likely classes\n",
    "  preds = preds.sort_values(ascending=False)\n",
    "\n",
    "  # return the top num_answers results in dict format\n",
    "  return preds[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test one with a fake review about history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with a fake review\n",
    "history_post = [ \"\"\"\n",
    "                History if my favorite subject.  I love to read historical accounts about ancient Rome and Greece.\n",
    "                I'm also a big World War 2 buff and I collect objects with historical significance.\n",
    "                \"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "history            0.6\n",
       "dadjokes           0.2\n",
       "books              0.1\n",
       "MachineLearning    0.1\n",
       "PS4                0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(history_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test two with a fake review about pokemon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try again and mention pokemon to see if the model correctly guesses pokemon:\n",
    "pokemon_post = [ \"\"\"\n",
    "                My favorite pokemon are pikachu and charizard. I love pokemon.  Pokemon is great.\n",
    "                \"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dadjokes    0.4\n",
       "Jokes       0.2\n",
       "pokemon     0.2\n",
       "webdev      0.1\n",
       "history     0.1\n",
       "dtype: float64"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(pokemon_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test three with a fake post about android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a fake prediction to see if android gets predicted:\n",
    "android_post = [ \"\"\"\n",
    "                I use a galaxy note 5.  My favorite opperating system version was oreo.\n",
    "                Android phones are better than iphones. I like to create apps for the app store.\n",
    "                \"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Android              0.4\n",
       "explainlikeimfive    0.2\n",
       "webdev               0.1\n",
       "LifeProTips          0.1\n",
       "dadjokes             0.1\n",
       "dtype: float64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(android_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test four with a fake post about music\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a fake prediction to see if music gets predicted:\n",
    "music_post = [ \"\"\"\n",
    "                I love to listen to music.  My favorite singer/songwriter is Foy Vance.  Every so often\n",
    "                I like to listen to Bob Marley.  I have a large vinyl music collection but more recently I've\n",
    "                been listening to everything on Spotify.\n",
    "                \"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Music              0.2\n",
       "askscience         0.2\n",
       "dadjokes           0.2\n",
       "TwoXChromosomes    0.1\n",
       "Fitness            0.1\n",
       "dtype: float64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(music_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test five with fake post about politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics_post = [\"\"\"\n",
    "                    Donald Trump and Bill Clinton.  Democrats, republicans and the tea party.\n",
    "                \"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Jokes       0.7\n",
       "dadjokes    0.3\n",
       "PS4         0.0\n",
       "buildapc    0.0\n",
       "books       0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_predictions(politics_post)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
